{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ml.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOG44x8LGOmPNZs+m3rSaDs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9x7Bv88fvS0K","executionInfo":{"status":"ok","timestamp":1638912805694,"user_tz":300,"elapsed":28741,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"e056ff8c-c868-4475-f7d2-ff7f1642f0ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,819 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,461 kB]\n","Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,446 kB]\n","Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [933 kB]\n","Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [691 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,898 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,227 kB]\n","Fetched 12.7 MB in 5s (2,540 kB/s)\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.2.0'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()\n"],"metadata":{"id":"ZTpLWrKm0Epf","executionInfo":{"status":"ok","timestamp":1638913529432,"user_tz":300,"elapsed":9455,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer"],"metadata":{"id":"XEDcmo993Dj8","executionInfo":{"status":"ok","timestamp":1638913899714,"user_tz":300,"elapsed":451,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# create sample df\n","dataframe = spark.createDataFrame([(0, \"Spark is great\"), (1, \"We are learning spark\"), (2, \"Spark is better than Hadoop no doubt\")], [\"id\", \"sentence\"])\n","dataframe.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2oVaGa34YcR","executionInfo":{"status":"ok","timestamp":1638914993987,"user_tz":300,"elapsed":7065,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"22e57426-07f3-459a-8044-8cf7e9246822"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|We are learning s...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"]}]},{"cell_type":"code","source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVLI3tLr4Ys5","executionInfo":{"status":"ok","timestamp":1638915297797,"user_tz":300,"elapsed":169,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"c8782ab9-2b6e-485e-8f55-ec8a07530ea7"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_4310ccc60cc0"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["tok_df = tokenizer.transform(dataframe)\n","tok_df.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VIgczmHn4YvG","executionInfo":{"status":"ok","timestamp":1638915407212,"user_tz":300,"elapsed":907,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"ae2ae48c-cd66-43a2-ff9e-ab21a9d97b6e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |\n","|1  |We are learning spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["# create a function that will enhance our tokenizer by returning a word count for each line\n","# Create a function to return the length of a list\n","def word_list_length(word_list):\n","    return len(word_list)\n","  \n","# import udf function, the col function to select a column to be passed into a function, and the type IntegerType that define the data type of the output\n","from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType\n","\n","# udf will take in the name of the function as a parameter and the output data type, which is the IntegerType that we just imported\n","# Create a user defined function\n","count_tokens = udf(word_list_length, IntegerType())\n","\n","# redo tokenizer process\n","# select needed results and dont truncate results\n","tok_df.withColumn(\"tokens\", count_tokens(col(\"words\"))).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90JVcVzV4YyJ","executionInfo":{"status":"ok","timestamp":1638916281267,"user_tz":300,"elapsed":1861,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"ada2f11e-85ae-45ba-8ed7-5a55896acb60"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great                      |[spark, is, great]                          |3     |\n","|1  |We are learning spark               |[we, are, learning, spark]                  |4     |\n","|2  |Spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"fgIW3UB24Y06"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"1cBnU5oe4Y2T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"LCg6NWS24Y4T"},"execution_count":null,"outputs":[]}]}