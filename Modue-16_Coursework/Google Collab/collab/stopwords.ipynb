{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"stopwords.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMMXvp5QuIuIxek0dD6T5gS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXO22k9-DKrt","executionInfo":{"status":"ok","timestamp":1638916905336,"user_tz":300,"elapsed":26744,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"b40be53c-3d80-4931-f576-fd51ad2b2216"},"outputs":[{"output_type":"stream","name":"stdout","text":["Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Ign:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:11 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,819 kB]\n","Ign:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,446 kB]\n","Hit:15 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [691 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,461 kB]\n","Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [933 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,898 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,227 kB]\n","Fetched 12.7 MB in 4s (3,154 kB/s)\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.2.0'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()\n"],"metadata":{"id":"RZJ60y_vDuNX","executionInfo":{"status":"ok","timestamp":1638916916360,"user_tz":300,"elapsed":7049,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# DataFrame that's already a list of words. By creating a list of words, we can skip the tokenization step for now\n","sentenceData = spark.createDataFrame([(0, [\"Big\", \"data\", \"is\", \"super\", \"powerful\"]), (1, [\"This\", \"is\", \"going\", \"to\",\"be\", \"epic\"])], [\"id\",\"raw\"])\n","sentenceData.show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fsgt9TpDuXF","executionInfo":{"status":"ok","timestamp":1638917249594,"user_tz":300,"elapsed":5816,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"51162a43-483a-4cc1-c067-44f99531c517"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------------------+\n","|id |raw                             |\n","+---+--------------------------------+\n","|0  |[Big, data, is, super, powerful]|\n","|1  |[This, is, going, to, be, epic] |\n","+---+--------------------------------+\n","\n"]}]},{"cell_type":"code","source":["# Import stop words library\n","from pyspark.ml.feature import StopWordsRemover\n"],"metadata":{"id":"kqMC5SVwDuZ-","executionInfo":{"status":"ok","timestamp":1638917282992,"user_tz":300,"elapsed":377,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Run the Remover\n","# input column + output column arguments\n","remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"filtered\")\n"],"metadata":{"id":"cZ6016o1Due8","executionInfo":{"status":"ok","timestamp":1638917356375,"user_tz":300,"elapsed":351,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# transform and show data\n","remover.transform(sentenceData).show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_3cJ14DDuhR","executionInfo":{"status":"ok","timestamp":1638917485164,"user_tz":300,"elapsed":1186,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"9f6b8d91-1c4b-4dd0-9916-69ab44c4620a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------------------+----------------------------+\n","|id |raw                             |filtered                    |\n","+---+--------------------------------+----------------------------+\n","|0  |[Big, data, is, super, powerful]|[Big, data, super, powerful]|\n","|1  |[This, is, going, to, be, epic] |[going, epic]               |\n","+---+--------------------------------+----------------------------+\n","\n"]}]},{"cell_type":"code","source":["# do both truncate and remover\n","from pyspark.ml.feature import Tokenizer\n","# create sample df\n","df = spark.createDataFrame([(0, \"Spark is great\"), (1, \"We are learning spark\"), (2, \"Spark is better than Hadoop no doubt\")], [\"id\", \"sentence\"])\n","df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FeKgXfzQDuj5","executionInfo":{"status":"ok","timestamp":1638917567791,"user_tz":300,"elapsed":378,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"df38a5fa-8440-49bc-99e4-7511f7998f98"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|We are learning s...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"]}]},{"cell_type":"code","source":["# Tokenize sentences\n","tok = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Cw0-D4DDumM","executionInfo":{"status":"ok","timestamp":1638917593856,"user_tz":300,"elapsed":344,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"db568045-2b0d-4d3a-86ef-3c3521b61c37"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_52e8ba72cc02"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["tok_df = tok.transform(df)\n","tok_df.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkHHS0D_Duoh","executionInfo":{"status":"ok","timestamp":1638917734088,"user_tz":300,"elapsed":582,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"abb6bf43-4936-47ac-945c-f3b284fff742"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |\n","|1  |We are learning spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["# Import stop words library\n","from pyspark.ml.feature import StopWordsRemover\n","\n","# Run the Remover\n","# input column + output column arguments\n","remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n","\n","remover.transform(tok_df).show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rNGISd4GnLO","executionInfo":{"status":"ok","timestamp":1638917858366,"user_tz":300,"elapsed":542,"user":{"displayName":"Taimur Ahmad Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHtaqODzbxHivCwKTHKr_riItzKRmWXtixBToR=s64","userId":"05627838692102361861"}},"outputId":"9f8c6007-b3dd-4483-c32e-7985452fef93"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+------------------------------+\n","|id |sentence                            |words                                       |filtered                      |\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |[spark, great]                |\n","|1  |We are learning spark               |[we, are, learning, spark]                  |[learning, spark]             |\n","|2  |Spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|[spark, better, hadoop, doubt]|\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","\n"]}]}]}